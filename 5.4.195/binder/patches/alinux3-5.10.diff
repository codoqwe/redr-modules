diff --git a/5.4.195/binder/binder_alloc.c b/5.4.195/binder/binder_alloc.c
index 1e72db8..661fc7f 100644
--- a/5.4.195/binder/binder_alloc.c
+++ b/5.4.195/binder/binder_alloc.c
@@ -214,7 +214,7 @@ static int binder_update_page_range(struct binder_alloc *alloc, int allocate,
 		mm = alloc->vma_vm_mm;
 
 	if (mm) {
-		down_read(&mm->mmap_sem);
+		down_read(&mm->mmap_lock);
 		vma = alloc->vma;
 	}
 
@@ -273,7 +273,7 @@ static int binder_update_page_range(struct binder_alloc *alloc, int allocate,
 		/* vm_insert_page does not seem to increment the refcount */
 	}
 	if (mm) {
-		up_read(&mm->mmap_sem);
+		up_read(&mm->mmap_lock);
 		mmput(mm);
 	}
 	return 0;
@@ -306,7 +306,7 @@ err_page_ptr_cleared:
 	}
 err_no_vma:
 	if (mm) {
-		up_read(&mm->mmap_sem);
+		up_read(&mm->mmap_lock);
 		mmput(mm);
 	}
 	return vma ? -ENOMEM : -ESRCH;
@@ -953,7 +953,7 @@ enum lru_status binder_alloc_free_page(struct list_head *item,
 	mm = alloc->vma_vm_mm;
 	if (!mmget_not_zero(mm))
 		goto err_mmget;
-	if (!down_read_trylock(&mm->mmap_sem))
+	if (!down_read_trylock(&mm->mmap_lock))
 		goto err_down_read_mmap_sem_failed;
 	vma = binder_alloc_get_vma(alloc);
 
@@ -967,7 +967,7 @@ enum lru_status binder_alloc_free_page(struct list_head *item,
 
 		trace_binder_unmap_user_end(alloc, index);
 	}
-	up_read(&mm->mmap_sem);
+	up_read(&mm->mmap_lock);
 	mmput_async(mm);
 
 	trace_binder_unmap_kernel_start(alloc, index);
